{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1pICRyehMzeh4ItylGLZwwHYBFsa3YReQ","authorship_tag":"ABX9TyOf814w1rcGYpPNFgCTKn3m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Transfer learning : MobileNet"],"metadata":{"id":"0tKS0rx0ewtA"}},{"cell_type":"markdown","source":["#Training and Predicting with MobileNetV2 for Multi-Class Image Classification\n","\n","About:\n","This code trains a deep learning model using MobileNetV2 for classifying images into three categories. It utilizes transfer learning with a pre-trained MobileNetV2 model, applies data augmentation, and includes early stopping for efficient training. After training the model, it evaluates the performance on a test set, saves the trained model, and predicts the class of new images. The results are visualized using matplotlib to display predictions alongside the corresponding images."],"metadata":{"id":"GiaN6C31XRII"}},{"cell_type":"markdown","source":["1. valiadtion accuracy 87\n","\n","2. validation accuracy 93"],"metadata":{"id":"Ow0w9MijXUJb"}},{"cell_type":"code","source":["# Import necessary libraries\n","from google.colab import drive\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import os\n","\n","# Mount Google Drive to access datasets\n","drive.mount('/content/drive')\n","\n","# Install TensorFlow if not already installed\n","!pip install tensorflow\n","\n","# Suppress warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Define image dimensions (MobileNetV2 standard input size)\n","img_height, img_width = 224, 224\n","\n","# Data augmentation and normalization using ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Define dataset directories\n","train_dir = '/content/drive/MyDrive/Classification/classidata/train'\n","valid_dir = '/content/drive/MyDrive/Classification/classidata/valid'\n","test_dir = '/content/drive/MyDrive/Classification/classidata/test'\n","\n","# Load datasets using flow_from_directory\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","valid_generator = valid_datagen.flow_from_directory(\n","    valid_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Load MobileNetV2 pre-trained model without the top layers (for transfer learning)\n","base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n","                                               include_top=False,  # Exclude the top layers (fully connected)\n","                                               weights='imagenet')  # Load pre-trained weights from ImageNet\n","\n","# Freeze the base model (to prevent re-training the base layers)\n","base_model.trainable = False\n","\n","# Create the new model on top of MobileNetV2\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),  # Global pooling instead of flatten\n","    layers.Dense(256, activation='relu'),  # Dense layer\n","    layers.Dropout(0.5),  # Dropout for regularization\n","    layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Early stopping callback when validation accuracy reaches above 90%\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n","                                                  patience=3,  # Number of epochs to wait after reaching 90%\n","                                                  min_delta=0.01,  # Minimum change to qualify as an improvement\n","                                                  mode='max',  # Stop when the validation accuracy reaches max value\n","                                                  verbose=1,\n","                                                  restore_best_weights=True)\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // 32,  # Number of batches per epoch\n","    epochs=15,  # Set the number of epochs to 15\n","    validation_data=valid_generator,\n","    validation_steps=valid_generator.samples // 32,  # Number of validation batches\n","    callbacks=[early_stopping]  # Include early stopping callback\n",")\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/Classification/classidata/best.h5')\n","print('Model saved!')\n","\n","# -------------------------------------------------------------\n","import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","import os\n","import numpy as np\n","\n","# Define path to new images for prediction\n","new_image_dir = '/content/drive/MyDrive/ooo'  # Replace with your new image directory path\n","\n","# Function to predict new images and display them\n","def predict_new_images(image_dir):\n","    # List all image files in the directory\n","    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n","\n","    # Iterate over each image\n","    for img_file in image_files:\n","        img_path = os.path.join(image_dir, img_file)\n","\n","        # Load and preprocess the image\n","        img = image.load_img(img_path, target_size=(img_height, img_width))\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","        img_array /= 255.0  # Normalize the image\n","\n","        # Make prediction\n","        predictions = model.predict(img_array)\n","\n","        # Get the predicted class (index of max probability)\n","        predicted_class = np.argmax(predictions, axis=1)\n","\n","        # Get the class label\n","        class_labels = list(train_generator.class_indices.keys())  # This gives you the class names from your training data\n","        predicted_label = class_labels[predicted_class[0]]\n","\n","        # Display the image and prediction result\n","        plt.imshow(img)\n","        plt.title(f\"Prediction: {predicted_label}\")\n","        plt.axis('off')  # Hide axes for a cleaner display\n","        plt.show()\n","\n","# Call the function to make predictions\n","predict_new_images(new_image_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yx2xWqq_IjsIsI9R44nl1BpFvEMQCFLL"},"id":"uFdftKmND_VJ","executionInfo":{"status":"ok","timestamp":1731165028969,"user_tz":-330,"elapsed":1312558,"user":{"displayName":"ADITYA MAHENDRAKAR","userId":"16199201624284344866"}},"outputId":"b27c672d-8284-4c0a-8640-f428db197bc7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Import necessary libraries\n","from google.colab import drive\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import os\n","\n","# Mount Google Drive to access datasets\n","drive.mount('/content/drive')\n","\n","# Install TensorFlow if not already installed\n","!pip install tensorflow\n","\n","# Suppress warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Define image dimensions (MobileNetV2 standard input size)\n","img_height, img_width = 224, 224\n","\n","# Data augmentation and normalization using ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Define dataset directories\n","train_dir = '/content/drive/MyDrive/Classification/classidata/train'\n","valid_dir = '/content/drive/MyDrive/Classification/classidata/valid'\n","test_dir = '/content/drive/MyDrive/Classification/classidata/test'\n","\n","# Load datasets using flow_from_directory\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","valid_generator = valid_datagen.flow_from_directory(\n","    valid_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Load MobileNetV2 pre-trained model without the top layers (for transfer learning)\n","base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n","                                               include_top=False,  # Exclude the top layers (fully connected)\n","                                               weights='imagenet')  # Load pre-trained weights from ImageNet\n","\n","# Freeze the base model (to prevent re-training the base layers)\n","base_model.trainable = False\n","\n","# Create the new model on top of MobileNetV2\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),  # Global pooling instead of flatten\n","    layers.Dense(256, activation='relu'),  # Dense layer\n","    layers.Dropout(0.5),  # Dropout for regularization\n","    layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // 32,  # Number of batches per epoch\n","    epochs=15,  # Set the number of epochs to 15\n","    validation_data=valid_generator,\n","    validation_steps=valid_generator.samples // 32  # Number of validation batches\n",")\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/Classification/classidata/mobilenetv2_best.h5')\n","print('Model saved!')\n","\n","# -------------------------------------------------------------\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blrp6GWdCMZK","executionInfo":{"status":"ok","timestamp":1731163260911,"user_tz":-330,"elapsed":5289153,"user":{"displayName":"ADITYA MAHENDRAKAR","userId":"16199201624284344866"}},"outputId":"08fa6e50-9a55-4fb9-8cbf-dd2587d7acb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Found 4782 images belonging to 3 classes.\n","Found 1026 images belonging to 3 classes.\n","Found 1026 images belonging to 3 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 13s/step - accuracy: 0.6459 - loss: 0.8548 - val_accuracy: 0.8447 - val_loss: 0.3735\n","Epoch 2/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3266 - val_accuracy: 0.5000 - val_loss: 0.5471\n","Epoch 3/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 2s/step - accuracy: 0.8476 - loss: 0.4173 - val_accuracy: 0.8809 - val_loss: 0.3058\n","Epoch 4/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8438 - loss: 0.2611 - val_accuracy: 1.0000 - val_loss: 0.2463\n","Epoch 5/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 2s/step - accuracy: 0.8808 - loss: 0.3183 - val_accuracy: 0.8779 - val_loss: 0.2957\n","Epoch 6/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.4635 - val_accuracy: 1.0000 - val_loss: 0.0230\n","Epoch 7/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 2s/step - accuracy: 0.8923 - loss: 0.2835 - val_accuracy: 0.9092 - val_loss: 0.2561\n","Epoch 8/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 984us/step - accuracy: 0.9062 - loss: 0.2212 - val_accuracy: 1.0000 - val_loss: 0.1176\n","Epoch 9/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 2s/step - accuracy: 0.8992 - loss: 0.2543 - val_accuracy: 0.9131 - val_loss: 0.2500\n","Epoch 10/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9688 - loss: 0.1874 - val_accuracy: 1.0000 - val_loss: 0.0039\n","Epoch 11/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 2s/step - accuracy: 0.9126 - loss: 0.2397 - val_accuracy: 0.9180 - val_loss: 0.2262\n","Epoch 12/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9688 - loss: 0.0854 - val_accuracy: 1.0000 - val_loss: 0.1505\n","Epoch 13/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 2s/step - accuracy: 0.9195 - loss: 0.2207 - val_accuracy: 0.9268 - val_loss: 0.2098\n","Epoch 14/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.9375 - loss: 0.1500 - val_accuracy: 1.0000 - val_loss: 0.0505\n","Epoch 15/15\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 2s/step - accuracy: 0.9150 - loss: 0.2168 - val_accuracy: 0.9219 - val_loss: 0.2050\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 14s/step - accuracy: 0.9365 - loss: 0.1710\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 93.96%\n","Model saved!\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","import os\n","import numpy as np\n","\n","# Define path to new images for prediction\n","new_image_dir = '/content/drive/MyDrive/ooo'  # Replace with your new image directory path\n","\n","# Function to predict new images and display them\n","def predict_new_images(image_dir):\n","    # List all image files in the directory\n","    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n","\n","    # Iterate over each image\n","    for img_file in image_files:\n","        img_path = os.path.join(image_dir, img_file)\n","\n","        # Load and preprocess the image\n","        img = image.load_img(img_path, target_size=(img_height, img_width))\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","        img_array /= 255.0  # Normalize the image\n","\n","        # Make prediction\n","        predictions = model.predict(img_array)\n","\n","        # Get the predicted class (index of max probability)\n","        predicted_class = np.argmax(predictions, axis=1)\n","\n","        # Get the class label\n","        class_labels = list(train_generator.class_indices.keys())  # This gives you the class names from your training data\n","        predicted_label = class_labels[predicted_class[0]]\n","\n","        # Display the image and prediction result\n","        plt.imshow(img)\n","        plt.title(f\"Prediction: {predicted_label}\")\n","        plt.axis('off')  # Hide axes for a cleaner display\n","        plt.show()\n","\n","# Call the function to make predictions\n","predict_new_images(new_image_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EtdF8sZMeMyS0YivbxVXAXX29k2x5eCD"},"id":"dp8FlzKpYEQQ","executionInfo":{"status":"ok","timestamp":1731163360777,"user_tz":-330,"elapsed":7882,"user":{"displayName":"ADITYA MAHENDRAKAR","userId":"16199201624284344866"}},"outputId":"bd63e9b3-fa3d-4666-d233-013f6ee27b12"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}